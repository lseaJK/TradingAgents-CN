断点续传（checkpoint/resume）在此类分析流程项目中，通常需要：

1. **保存中间状态**：在每个关键步骤或阶段，将当前 final_state（或其他重要变量）序列化保存到磁盘（如 JSON 文件）。
2. **异常处理**：用 `try...except` 捕获异常，遇到错误时记录日志，并保存当前状态，便于下次恢复。
3. **恢复机制**：启动时检测是否有已保存的中间状态，如果有则加载并从该状态继续执行。

### 实现建议

#### 1. 保存中间状态

在 analyze_and_report 的关键步骤后加入保存：

```python
import json

def save_checkpoint(state, path):

    with open(path, "w", encoding="utf-8") as f:

        json.dump(state, f, ensure_ascii=False, indent=2)

def load_checkpoint(path):

    if Path(path).exists():

        with open(path, "r", encoding="utf-8") as f:

            return json.load(f)

    return None
```

#### 2. 异常处理与断点保存

```python
def analyze_and_report(ticker: str, analysis_date: str, debug: bool = True):
    config = DEFAULT_CONFIG.copy()
    results_dir = Path(config["results_dir"]) / ticker / analysis_date
    checkpoint_path = results_dir / "checkpoint.json"
    report_dir = results_dir / "reports"
    results_dir.mkdir(parents=True, exist_ok=True)
    report_dir.mkdir(parents=True, exist_ok=True)

    ta = TradingAgentsGraph(debug=debug, config=config)

    # 尝试加载断点

    final_state = load_checkpoint(checkpoint_path)
    if final_state:
        console.print(Panel("Resuming from checkpoint...", title="Resume", border_style="yellow"))
    try:
        if not final_state:
            final_state, decision = ta.propagate(ticker, analysis_date)
            save_checkpoint(final_state, checkpoint_path)
        else:
            # 如果有断点，直接生成报告和决策
            decision = final_state.get("final_trade_decision", "No decision found")
        save_reports(final_state, report_dir)
        display_complete_report(final_state)
        console.print(Panel(Markdown(f"## Final Decision\n\n{decision}"), title="Signal", border_style="green"))
        (results_dir / "decision.txt").write_text(str(decision), encoding="utf-8")
        return decision

    except Exception as e:
        logger.error(f"Error: {e}")
        if final_state:
            save_checkpoint(final_state, checkpoint_path)
        raise
```

#### 3. 启动时自动恢复

只需在 analyze_and_report 开头检测 checkpoint 文件并加载即可。

---

**总结**：

- 每步保存 final_state 到 checkpoint 文件。
- 异常时自动保存当前状态。
- 下次启动时自动检测并恢复断点。
- 日志记录异常，便于排查。

如需更细粒度断点，可在 TradingAgentsGraph 内部各阶段也加入 checkpoint 逻辑。

### GitHub Copilot

Used 1 reference

你的理解是对的：  
如果是通过 `graph.stream` 或类似流程驱动，每个节点（agent/step）都可能有自己的状态和输出。断点续传要实现得细致，确实需要**每个节点执行前都判断是否已完成**，并能恢复到该节点。

### 实现思路

1. **节点级状态保存**
   
   - 每个节点执行前，检查本节点的状态是否已存在于 checkpoint（如 JSON 文件）。
   - 如果存在，跳过执行，直接用已保存结果。
   - 如果不存在，正常执行，并在执行后保存节点状态。

2. **全局状态管理**
   
   - 可以设计一个 `state_manager`，每次节点执行后自动保存整个流程的状态（包括每个节点的结果）。
   - 恢复时，加载 checkpoint，流程只执行未完成的节点。

3. **代码示例（伪代码）**

```python
# 在每个节点执行前

def run_node(node_name, state, ...):

    checkpoint = load_checkpoint()

    if checkpoint and node_name in checkpoint["completed_nodes"]:

        logger.info(f"Node {node_name} already completed, skipping.")

        return checkpoint["node_results"][node_name]

    # 正常执行

    result = node_execute(...)

    # 保存节点结果

    checkpoint["completed_nodes"].append(node_name)

    checkpoint["node_results"][node_name] = result

    save_checkpoint(checkpoint)

    return result
```

### 你需要做的

- 在 graph/propagation 或 agent 执行逻辑里，**每个节点前都加断点判断和保存**。
- 可以用一个全局 dict 记录所有节点的完成情况和结果。
- 这样即使流程中断，下次启动时只需恢复未完成的节点。

---

**总结**：

- 理想化的断点续传确实需要每个节点都能独立判断和恢复。
- 推荐在每个节点执行前后加 checkpoint 逻辑。
- 这样可以实现真正的流程级断点续传和恢复。

要在你的 TradingAgents 项目中实现断点续传，建议采用**节点级断点**，即每个 graph 节点执行前后都进行状态检查和保存。这样即使流程中断，下次可从已完成节点继续。

#### 1. 设计断点数据结构

在 final_state 中增加一个 `completed_nodes` 字典，记录每个节点的执行结果。例如：

```
# final_state["completed_nodes"] = {
#     "Market Analyst": {...},
#     "Bull Researcher": {...},
#     ...
# }
```

#### 2. 节点执行前检查断点

在每个节点的执行逻辑（如 agent node 或 graph stream handler）前，判断该节点是否已完成：

```python
def run_node(node_name, state, *args, **kwargs):
    completed = state.get("completed_nodes", {})
    if node_name in completed:
        logger.info(f"断点恢复：{node_name} 已完成，跳过执行。")
        return completed[node_name]  # 直接返回已保存结果
    result = actual_node_execute(*args, **kwargs)
    completed[node_name] = result
    state["completed_nodes"] = completed
    save_checkpoint(state)  # 每步都保存
    return result
```

#### 3. 保存与加载断点

在每步执行后保存 final_state 到磁盘（如 JSON 文件），启动时自动加载：

```python
import json

def save_checkpoint(state, path):

    with open(path, "w", encoding="utf-8") as f:

        json.dump(state, f, ensure_ascii=False, indent=2)

def load_checkpoint(path):

    if Path(path).exists():

        with open(path, "r", encoding="utf-8") as f:

            return json.load(f)

    return None
```

#### 4. 在主流程中集成断点机制

在 TradingAgentsGraph.propagate 或 graph stream 主循环中，加载断点并在每个节点前后调用上述逻辑。

#### 5. 错误处理

遇到异常时，自动保存当前状态，便于下次恢复。

---

### 总结

- **每个节点执行前检查断点，已完成则跳过。**
- **每步执行后保存状态到 checkpoint 文件。**
- **启动时自动加载 checkpoint，恢复流程。**
- **遇到异常自动保存断点。**

这样可以实现真正的流程级断点续传，最大程度减少重复计算和数据丢失。





# 每日每股断点隔离

要将断点续传机制应用到你的 TradingAgents 项目，建议如下：

### 1. 设计断点数据结构

在 `final_state` 增加 `completed_nodes` 字典，记录每个节点的执行结果。

### 2. 节点执行前检查断点

在每个节点的 handler（如 agent node 或工具 node）前，判断该节点是否已完成，已完成则直接返回结果，否则正常执行并保存。

### 3. 保存与加载断点

在每步执行后保存 `final_state` 到 checkpoint 文件，启动时自动加载。

### 4. 集成到 graph stream 主循环

在 `TradingAgentsGraph.propagate` 或 graph stream handler 中，加载断点并在每个节点前后调用上述逻辑。

具体代码实现建议：

#### a) 新建 checkpoint 工具函数（如 tradingagents/utils/checkpoint.py）

```python
import json

from pathlib import Path

def save_checkpoint(state, path):

    with open(path, "w", encoding="utf-8") as f:

        json.dump(state, f, ensure_ascii=False, indent=2)

def load_checkpoint(path):

    if Path(path).exists():

        with open(path, "r", encoding="utf-8") as f:

            return json.load(f)

    return None
```

#### b) 在 `TradingAgentsGraph.propagate` 或主流程中集成断点机制

每个股票、每一天都要有独立的 checkpoint 文件，路径为  
Path(config["results_dir"]) / ticker / analysis_date / "checkpoint.json"

这样可以实现每日、每股的断点隔离，互不影响。

---

### 推荐修改方案

在 TradingAgentsGraph.propagate 方法中：

1. 用 self.config["results_dir"]、company_name、trade_date 构造 checkpoint 路径。
2. checkpoint 路径为：  
   Path(self.config["results_dir"]) / company_name / trade_date / "checkpoint.json"
3. 断点加载、保存都用这个路径。

```python
    def propagate(self, company_name, trade_date):
        """Run the trading agents graph for a company on a specific date."""

        # 添加详细的接收日志
        logger.debug(f"🔍 [GRAPH DEBUG] ===== TradingAgentsGraph.propagate 接收参数 =====")
        logger.debug(f"🔍 [GRAPH DEBUG] 接收到的company_name: '{company_name}' (类型: {type(company_name)})")
        logger.debug(f"🔍 [GRAPH DEBUG] 接收到的trade_date: '{trade_date}' (类型: {type(trade_date)})")

        self.ticker = company_name
        logger.debug(f"🔍 [GRAPH DEBUG] 设置self.ticker: '{self.ticker}'")
    
        # 设置每日每股独立断点路径
        checkpoint_dir = Path(self.config["results_dir"]) / company_name / trade_date
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        checkpoint_path = checkpoint_dir / "checkpoint.json"

        # 加载 checkpoint 或新建初始状态
        if checkpoint_path.exists():
            with open(checkpoint_path, "r", encoding="utf-8") as f:
                init_agent_state = json.load(f)
            logger.info(f"断点恢复：已加载 checkpoint 状态。")
        else:
            init_agent_state = self.propagator.create_initial_state(company_name, trade_date)
            logger.info(f"未发现 checkpoint，使用新初始状态。")

        # Initialize state
        logger.debug(f"🔍 [GRAPH DEBUG] 创建初始状态，传递参数: company_name='{company_name}', trade_date='{trade_date}'")
        init_agent_state = self.propagator.create_initial_state(
            company_name, trade_date
        )
        logger.debug(f"🔍 [GRAPH DEBUG] 初始状态中的company_of_interest: '{init_agent_state.get('company_of_interest', 'NOT_FOUND')}'")
        logger.debug(f"🔍 [GRAPH DEBUG] 初始状态中的trade_date: '{init_agent_state.get('trade_date', 'NOT_FOUND')}'")
        args = self.propagator.get_graph_args()

        try:
            if self.debug:
                trace = []
                for chunk in self.graph.stream(init_agent_state, **args):
                    if len(chunk["messages"]) == 0:
                        pass
                    else:
                        chunk["messages"][-1].pretty_print()
                        # 保存 checkpoint
                        with open(checkpoint_path, "w", encoding="utf-8") as f:
                            json.dump(chunk, f, ensure_ascii=False, indent=2, cls=CustomEncoder)
                        trace.append(chunk)
                final_state = trace[-1]
            else:
                final_state = self.graph.invoke(init_agent_state, **args)
                # 保存 checkpoint
                with open(checkpoint_path, "w", encoding="utf-8") as f:
                    json.dump(final_state, f, ensure_ascii=False, indent=2)
        except Exception as e:
            # 异常时保存当前状态
            with open(checkpoint_path, "w", encoding="utf-8") as f:
                json.dump(init_agent_state, f, ensure_ascii=False, indent=2)
            logger.error(f"propagate异常: {e}")
            raise 
  
            # Store current state for reflection
        self.curr_state = final_state

        # Log state
        self._log_state(trade_date, final_state)

        # Return decision and processed signal
        return final_state, self.process_signal(final_state["final_trade_decision"], company_name)
```

**流程中断点恢复的状态一致性**

- 如果流程中有其他状态（如内存、日志、缓存等），确保它们与 checkpoint 恢复时一致。
- 比如，如果 final_state 里有 `completed_nodes` 或其他进度标记，建议在 create_initial_state 里也初始化这些字段。

```python
    def create_initial_state(
        self, company_name: str, trade_date: str
    ) -> Dict[str, Any]:
        """Create the initial state for the agent graph."""
        return {
            "messages": [("human", company_name)],
            "company_of_interest": company_name,
            "trade_date": str(trade_date),
            "investment_debate_state": InvestDebateState(
                {"history": "", "current_response": "", "count": 0}
            ),
            "risk_debate_state": RiskDebateState(
                {
                    "history": "",
                    "current_risky_response": "",
                    "current_safe_response": "",
                    "current_neutral_response": "",
                    "count": 0,
                }
            ),
            "market_report": "",
            "fundamentals_report": "",
            "sentiment_report": "",
            "news_report": "",
            # 新增断点进度字段，便于断点续传
            "completed_nodes": {},
        }

    def get_graph_args(self) -> Dict[str, Any]:
        """Get arguments for the graph invocation."""
        return {
            "stream_mode": "values",
            "config": {"recursion_limit": self.max_recur_limit},
        }


```

chunk内容如下，由于 chunk 里包含了 `HumanMessage` 或其他自定义对象，这些对象不能直接被 json 序列化。所以直接dump会报错，需要包装一下，保存到`tradingagents/utils/checkpoints.py`
{'messages': [HumanMessage(content='300476', additional_kwargs={}, response_metadata={}, id='0df1e721-af66-4c39-8060-9bc0cade01d3')], 'company_of_interest': '300476', 'trade_date': '2025-08-20', 'market_report': '', 'sentiment_report': '', 'news_report': '', 'fundamentals_report': '', 'investment_debate_state': {'history': '', 'current_response': '', 'count': 0}, 'risk_debate_state': {'history': '', 'current_risky_response': '', 'current_safe_response': '', 'current_neutral_response': '', 'count': 0}}

```python
import json
from pathlib import Path

def save_checkpoint(state, path):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def load_checkpoint(path):
    if Path(path).exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    r
eturn None

# 不能序列化内容包装
class CustomEncoder(json.JSONEncoder):
    def default(self, obj):
        if hasattr(obj, 'dict'):
            return obj.dict()
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        return str(obj)
# 用法
# json.dump(chunk, f, ensure_ascii=False, indent=2, cls=CustomEncoder)
```

**节点是否已执行的判断和跳过逻辑**还没有在主流程或节点执行处实现。

你需要做什么？

1. **在每个节点执行前，判断 completed_nodes 是否已包含该节点结果**
   
   - 如果已完成，则直接跳过该节点或返回已保存结果。
   - 如果未完成，则正常执行，并在执行后保存结果到 completed_nodes。

2. **推荐实现位置**
   
   - 如果你有节点执行的统一入口（如 `run_node` 或 graph handler），就在这里加判断。
   - 如果是 langgraph/StateGraph 自动调度节点，可以在每个 node handler 里加判断。

示例代码（伪代码）

假设你有如下节点执行逻辑：

```python
def run_node(node_name, state, *args, **kwargs):
    completed = state.get("completed_nodes", {})
    if node_name in completed:
        logger.info(f"断点恢复：{node_name} 已完成，跳过执行。")
        return completed[node_name]  # 直接返回已保存结果
    result = actual_node_execute(node_name, state, *args, **kwargs)
    completed[node_name] = result
    state["completed_nodes"] = completed
    # 保存 checkpoint
    save_checkpoint(state)
    return result
```

集成到你的项目

- 在每个节点 handler 或 graph 执行入口加如上判断。
- 这样，断点恢复时会自动跳过已完成节点，只执行未完成部分。

---

**总结**：  
你已经实现了节点状态保存，但还需在节点执行入口加“是否已完成”判断和跳过逻辑，才能实现真正的断点续传。  

1）**在每个节点执行前，判断 completed_nodes 是否已包含该节点结果**

- 如果已完成，则直接跳过该节点或返回已保存结果。
- 如果未完成，则正常执行，并在执行后保存结果到 completed_nodes。

**推荐实现位置**

- 如果你有节点执行的统一入口（如 `run_node` 或 graph handler），就在这里加判断。
- 如果是 langgraph/StateGraph 自动调度节点，可以在每个 node handler 里加判断。

2）ToolNode 不是一个可调用对象（不是函数），而是一个类实例，不能像函数一样直接调用。

如果 ToolNode 不能包装断点逻辑，那么在 workflow 的边（edge）选择时，应该根据 `completed_nodes` 判断是否跳过 tool_node，直接流向下一个节点。

**推荐实现方式**：在 conditional_edges 的条件函数里加判断

- 让条件函数（如 `should_continue_market`）检查 state["completed_nodes"] 是否已包含 tool_node 或当前节点结果。
- 如果已完成，则直接返回下一个节点（如 clear/msg/下一个 analyst），否则正常流向 tool_node。
  
  

原来的market到tool和clear节点已经是条件边了，所以现在只需要增加条件判断的逻辑即可。修改原先的四个分析师条件代码即可。

```python
# TradingAgents/graph/conditional_logic.py
    def should_continue_market(self, state: AgentState):
        """Determine if market analysis should continue."""
        # 断点续传：如果tools_market已完成则直接跳过
        if "tools_market" in state.get("completed_nodes", {}):
            return "Msg Clear Market"
        messages = state["messages"]
        last_message = messages[-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools_market"
        return "Msg Clear Market"

    def should_continue_social(self, state: AgentState):
        """Determine if social media analysis should continue."""
        if "tools_social" in state.get("completed_nodes", {}):
            return "Msg Clear Social"
        messages = state["messages"]
        last_message = messages[-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools_social"
        return "Msg Clear Social"

    def should_continue_news(self, state: AgentState):
        """Determine if news analysis should continue."""
        if "tools_news" in state.get("completed_nodes", {}):
            return "Msg Clear News"
        messages = state["messages"]
        last_message = messages[-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools_news"
        return "Msg Clear News"

    def should_continue_fundamentals(self, state: AgentState):
        """Determine if fundamentals analysis should continue."""
        if "tools_fundamentals" in state.get("completed_nodes", {}):
            return "Msg Clear Fundamentals"
        messages = state["messages"]
        last_message = messages[-1]
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools_fundamentals"
        return "Msg Clear Fundamentals"
```

```python
# TradingAgents/graph/setup.py

from typing import Dict, Any
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph, START
from langgraph.prebuilt import ToolNode

from tradingagents.agents import *
from tradingagents.agents.utils.agent_states import AgentState
from tradingagents.agents.utils.agent_utils import Toolkit

from .conditional_logic import ConditionalLogic

# 导入统一日志系统
from tradingagents.utils.logging_init import get_logger
logger = get_logger("default")


# 节点执行断点续传逻辑
def node_with_checkpoint(node_name, node_func):
    def wrapper(state, *args, **kwargs):
        completed = state.get("completed_nodes", {})
        if node_name in completed:
            logger.info(f"断点恢复：{node_name} 已完成，跳过执行。")
            return completed[node_name]
        result = node_func(state, *args, **kwargs)
        completed[node_name] = result
        state["completed_nodes"] = completed
        return result
    return wrapper

class GraphSetup:
    """Handles the setup and configuration of the agent graph."""

    def __init__(
        self,
        quick_thinking_llm: ChatOpenAI,
        deep_thinking_llm: ChatOpenAI,
        toolkit: Toolkit,
        tool_nodes: Dict[str, ToolNode],
        bull_memory,
        bear_memory,
        trader_memory,
        invest_judge_memory,
        risk_manager_memory,
        conditional_logic: ConditionalLogic,
        config: Dict[str, Any] = None,
        react_llm = None,
    ):
        """Initialize with required components."""
        self.quick_thinking_llm = quick_thinking_llm
        self.deep_thinking_llm = deep_thinking_llm
        self.toolkit = toolkit
        self.tool_nodes = tool_nodes
        self.bull_memory = bull_memory
        self.bear_memory = bear_memory
        self.trader_memory = trader_memory
        self.invest_judge_memory = invest_judge_memory
        self.risk_manager_memory = risk_manager_memory
        self.conditional_logic = conditional_logic
        self.config = config or {}
        self.react_llm = react_llm


    def setup_graph(
        self, selected_analysts=["market", "social", "news", "fundamentals"]
    ):
        """Set up and compile the agent workflow graph.

        Args:
            selected_analysts (list): List of analyst types to include. Options are:
                - "market": Market analyst
                - "social": Social media analyst
                - "news": News analyst
                - "fundamentals": Fundamentals analyst
        """
        if len(selected_analysts) == 0:
            raise ValueError("Trading Agents Graph Setup Error: no analysts selected!")

        # Create analyst nodes
        analyst_nodes = {}
        delete_nodes = {}
        tool_nodes = {}

        if "market" in selected_analysts:
            # 现在所有LLM都使用标准市场分析师（包括阿里百炼的OpenAI兼容适配器）
            llm_provider = self.config.get("llm_provider", "").lower()

            # 检查是否使用OpenAI兼容的阿里百炼适配器
            using_dashscope_openai = (
                "dashscope" in llm_provider and
                hasattr(self.quick_thinking_llm, '__class__') and
                'OpenAI' in self.quick_thinking_llm.__class__.__name__
            )

            if using_dashscope_openai:
                logger.debug(f"📈 [DEBUG] 使用标准市场分析师（阿里百炼OpenAI兼容模式）")
            elif "dashscope" in llm_provider or "阿里百炼" in self.config.get("llm_provider", ""):
                logger.debug(f"📈 [DEBUG] 使用标准市场分析师（阿里百炼原生模式）")
            elif "deepseek" in llm_provider:
                logger.debug(f"📈 [DEBUG] 使用标准市场分析师（DeepSeek）")
            else:
                logger.debug(f"📈 [DEBUG] 使用标准市场分析师")

            # 所有LLM都使用标准分析师
            analyst_nodes["market"] = create_market_analyst(
                self.quick_thinking_llm, self.toolkit
            )
            delete_nodes["market"] = create_msg_delete()
            tool_nodes["market"] = self.tool_nodes["market"]

        if "social" in selected_analysts:
            analyst_nodes["social"] = create_social_media_analyst(
                self.quick_thinking_llm, self.toolkit
            )
            delete_nodes["social"] = create_msg_delete()
            tool_nodes["social"] = self.tool_nodes["social"]

        if "news" in selected_analysts:
            analyst_nodes["news"] = create_news_analyst(
                self.quick_thinking_llm, self.toolkit
            )
            delete_nodes["news"] = create_msg_delete()
            tool_nodes["news"] = self.tool_nodes["news"]

        if "fundamentals" in selected_analysts:
            # 现在所有LLM都使用标准基本面分析师（包括阿里百炼的OpenAI兼容适配器）
            llm_provider = self.config.get("llm_provider", "").lower()

            # 检查是否使用OpenAI兼容的阿里百炼适配器
            using_dashscope_openai = (
                "dashscope" in llm_provider and
                hasattr(self.quick_thinking_llm, '__class__') and
                'OpenAI' in self.quick_thinking_llm.__class__.__name__
            )

            if using_dashscope_openai:
                logger.debug(f"📊 [DEBUG] 使用标准基本面分析师（阿里百炼OpenAI兼容模式）")
            elif "dashscope" in llm_provider or "阿里百炼" in self.config.get("llm_provider", ""):
                logger.debug(f"📊 [DEBUG] 使用标准基本面分析师（阿里百炼原生模式）")
            elif "deepseek" in llm_provider:
                logger.debug(f"📊 [DEBUG] 使用标准基本面分析师（DeepSeek）")
            else:
                logger.debug(f"📊 [DEBUG] 使用标准基本面分析师")

            # 所有LLM都使用标准分析师（包含强制工具调用机制）
            analyst_nodes["fundamentals"] = create_fundamentals_analyst(
                self.quick_thinking_llm, self.toolkit
            )
            delete_nodes["fundamentals"] = create_msg_delete()
            tool_nodes["fundamentals"] = self.tool_nodes["fundamentals"]

        # Create researcher and manager nodes
        bull_researcher_node = create_bull_researcher(
            self.quick_thinking_llm, self.bull_memory
        )
        bear_researcher_node = create_bear_researcher(
            self.quick_thinking_llm, self.bear_memory
        )
        research_manager_node = create_research_manager(
            self.deep_thinking_llm, self.invest_judge_memory
        )
        trader_node = create_trader(self.quick_thinking_llm, self.trader_memory)

        # Create risk analysis nodes
        risky_analyst = create_risky_debator(self.quick_thinking_llm)
        neutral_analyst = create_neutral_debator(self.quick_thinking_llm)
        safe_analyst = create_safe_debator(self.quick_thinking_llm)
        risk_manager_node = create_risk_manager(
            self.deep_thinking_llm, self.risk_manager_memory
        )

        # Create workflow
        workflow = StateGraph(AgentState)

        # 包装所有 analyst/researcher/manager/risk/trader 节点
        for analyst_type, node in analyst_nodes.items():
            workflow.add_node(f"{analyst_type.capitalize()} Analyst", node_with_checkpoint(f"{analyst_type.capitalize()} Analyst", node))
            workflow.add_node(
                f"Msg Clear {analyst_type.capitalize()}", node_with_checkpoint(f"Msg Clear {analyst_type.capitalize()}", delete_nodes[analyst_type])
            )
            workflow.add_node(f"tools_{analyst_type}", node_with_checkpoint(f"tools_{analyst_type}", tool_nodes[analyst_type]))


        workflow.add_node("Bull Researcher", node_with_checkpoint("Bull Researcher", bull_researcher_node))
        workflow.add_node("Bear Researcher", node_with_checkpoint("Bear Researcher", bear_researcher_node))
        workflow.add_node("Research Manager", node_with_checkpoint("Research Manager", research_manager_node))
        workflow.add_node("Trader", node_with_checkpoint("Trader", trader_node))
        workflow.add_node("Risky Analyst", node_with_checkpoint("Risky Analyst", risky_analyst))
        workflow.add_node("Neutral Analyst", node_with_checkpoint("Neutral Analyst", neutral_analyst))
        workflow.add_node("Safe Analyst", node_with_checkpoint("Safe Analyst", safe_analyst))
        workflow.add_node("Risk Judge", node_with_checkpoint("Risk Judge", risk_manager_node))

        # Define edges
        # Start with the first analyst
        first_analyst = selected_analysts[0]
        workflow.add_edge(START, f"{first_analyst.capitalize()} Analyst")

        # Connect analysts in sequence
        for i, analyst_type in enumerate(selected_analysts):
            current_analyst = f"{analyst_type.capitalize()} Analyst"
            current_tools = f"tools_{analyst_type}"
            current_clear = f"Msg Clear {analyst_type.capitalize()}"

            # Add conditional edges for current analyst
            workflow.add_conditional_edges(
                current_analyst,
                getattr(self.conditional_logic, f"should_continue_{analyst_type}"),
                [current_tools, current_clear],
            )
            workflow.add_edge(current_tools, current_analyst)

            # Connect to next analyst or to Bull Researcher if this is the last analyst
            if i < len(selected_analysts) - 1:
                next_analyst = f"{selected_analysts[i+1].capitalize()} Analyst"
                workflow.add_edge(current_clear, next_analyst)
            else:
                workflow.add_edge(current_clear, "Bull Researcher")

        # Add remaining edges
        workflow.add_conditional_edges(
            "Bull Researcher",
            self.conditional_logic.should_continue_debate,
            {
                "Bear Researcher": "Bear Researcher",
                "Research Manager": "Research Manager",
            },
        )
        workflow.add_conditional_edges(
            "Bear Researcher",
            self.conditional_logic.should_continue_debate,
            {
                "Bull Researcher": "Bull Researcher",
                "Research Manager": "Research Manager",
            },
        )
        workflow.add_edge("Research Manager", "Trader")
        workflow.add_edge("Trader", "Risky Analyst")
        workflow.add_conditional_edges(
            "Risky Analyst",
            self.conditional_logic.should_continue_risk_analysis,
            {
                "Safe Analyst": "Safe Analyst",
                "Risk Judge": "Risk Judge",
            },
        )
        workflow.add_conditional_edges(
            "Safe Analyst",
            self.conditional_logic.should_continue_risk_analysis,
            {
                "Neutral Analyst": "Neutral Analyst",
                "Risk Judge": "Risk Judge",
            },
        )
        workflow.add_conditional_edges(
            "Neutral Analyst",
            self.conditional_logic.should_continue_risk_analysis,
            {
                "Risky Analyst": "Risky Analyst",
                "Risk Judge": "Risk Judge",
            },
        )

        workflow.add_edge("Risk Judge", END)

        # Compile and return
        return workflow.compile()


```